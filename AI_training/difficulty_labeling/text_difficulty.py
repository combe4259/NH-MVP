# -*- coding: utf-8 -*-
"""text_difficulty.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/112GWo0LrRls5B_uF6ghjZXzY6PxXzrnV
"""

!pip install transformers datasets accelerate scikit-learn

"""
KLUE-BERT Fine-tuning for Text Difficulty Classification
ê¸ˆìœµ ë¬¸ì„œ ë‚œì´ë„ ë¶„ë¥˜ë¥¼ ìœ„í•œ KLUE-BERT íŒŒì¸íŠœë‹
"""

import torch
from torch.utils.data import Dataset, DataLoader
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
    EarlyStoppingCallback
)
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix
from sklearn.utils.class_weight import compute_class_weight
import pandas as pd
import numpy as np
import json
import os
import glob
from tqdm import tqdm
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
import warnings
warnings.filterwarnings('ignore')

class TextDifficultyDataset(Dataset):
    """í…ìŠ¤íŠ¸ ë‚œì´ë„ ë°ì´í„°ì…‹"""

    def __init__(self, texts, labels, tokenizer, max_length=512):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        text = str(self.texts[idx])
        label = self.labels[idx]

        # í† í¬ë‚˜ì´ì§•
        encoding = self.tokenizer(
            text,
            truncation=True,
            padding='max_length',
            max_length=self.max_length,
            return_tensors='pt'
        )

        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'labels': torch.tensor(label, dtype=torch.long)
        }

def load_data(json_path):
    """JSON ë°ì´í„° ë¡œë“œ"""
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    texts = []
    labels = []

    for item in data:
        texts.append(item['text'])
        # labelì´ 0-9ë©´ ê·¸ëŒ€ë¡œ, difficultyê°€ 1-10ì´ë©´ -1
        if 'label' in item:
            labels.append(item['label'])  # 0-indexed (0-9)
        else:
            labels.append(item['difficulty'] - 1)  # 1-10 â†’ 0-9

    return texts, labels

def compute_metrics(eval_pred):
    """í‰ê°€ ë©”íŠ¸ë¦­ ê³„ì‚°"""
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=1)

    # ì •í™•ë„
    accuracy = accuracy_score(labels, predictions)

    # Precision, Recall, F1
    precision, recall, f1, _ = precision_recall_fscore_support(
        labels, predictions, average='weighted', zero_division=0
    )

    # MAE (Mean Absolute Error) - ë‚œì´ë„ ì°¨ì´
    mae = np.mean(np.abs(predictions - labels))

    # Â±1 ë²”ìœ„ ë‚´ ì •í™•ë„ (ë‚œì´ë„ 1 ì°¨ì´ëŠ” í—ˆìš©)
    within_1 = np.mean(np.abs(predictions - labels) <= 1)

    return {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'mae': mae,
        'within_1_acc': within_1  # ì¶”ê°€: 1ë‹¨ê³„ ì°¨ì´ ë‚´ ì •í™•ë„
    }

def plot_confusion_matrix(y_true, y_pred, save_path=None):
    """í˜¼ë™ í–‰ë ¬ ì‹œê°í™”"""
    cm = confusion_matrix(y_true, y_pred)

    plt.figure(figsize=(12, 10))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title('Confusion Matrix - Text Difficulty Classification')
    plt.xlabel('Predicted Difficulty')
    plt.ylabel('True Difficulty')

    # ë ˆì´ë¸” ì„¤ì • (1-10)
    tick_labels = [str(i+1) for i in range(10)]
    plt.xticks(np.arange(10) + 0.5, tick_labels)
    plt.yticks(np.arange(10) + 0.5, tick_labels)

    if save_path:
        plt.savefig(save_path, dpi=100, bbox_inches='tight')
    plt.show()

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""

    # ===== Colab í™˜ê²½ í™•ì¸ =====
    try:
        from google.colab import drive
        drive.mount('/content/drive')
        print(" Google Drive ë§ˆìš´íŠ¸ ì™„ë£Œ")
        is_colab = True
    except:
        print(" ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘...")
        is_colab = False

    # ===== ì„¤ì • =====
    MODEL_NAME = "klue/bert-base"

    # íŒŒì¼ ê²½ë¡œ ì„¤ì • (Colab vs ë¡œì»¬)
    if is_colab:
        # Colabì—ì„œ Google Drive ê²½ë¡œ
        BASE_DIR = "/content/drive/MyDrive"
        JSON_PATH = f"{BASE_DIR}/text_difficulty_labels/training_data_20250910_092856.json"
        OUTPUT_DIR = f"{BASE_DIR}/klue_bert_difficulty_model"

        # JSON íŒŒì¼ì´ ì—†ìœ¼ë©´ ë‹¤ë¥¸ ê²½ë¡œ ì‹œë„
        if not os.path.exists(JSON_PATH):
            # ê°€ì¥ ìµœê·¼ JSON íŒŒì¼ ì°¾ê¸°
            import glob
            json_files = glob.glob(f"{BASE_DIR}/text_difficulty_labels/training_data_*.json")
            if json_files:
                JSON_PATH = sorted(json_files)[-1]  # ê°€ì¥ ìµœê·¼ íŒŒì¼
                print(f" JSON íŒŒì¼ ì‚¬ìš©: {JSON_PATH.split('/')[-1]}")
            else:
                print(" JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
                print(f"   ê²½ë¡œ: {BASE_DIR}/text_difficulty_labels/")
                return None, None
    else:
        # ë¡œì»¬ ê²½ë¡œ
        JSON_PATH = "/Users/inter4259/Downloads/training_data_20250910_092856.json"
        OUTPUT_DIR = "./klue_bert_difficulty_model"

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    print(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {OUTPUT_DIR}")

    # í•˜ì´í¼íŒŒë¼ë¯¸í„°
    MAX_LENGTH = 512
    BATCH_SIZE = 16  # GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •
    LEARNING_RATE = 2e-5
    NUM_EPOCHS = 10
    WARMUP_STEPS = 500

    # GPU ì„¤ì •
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f" ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
    if device.type == 'cuda':
        print(f"   GPU: {torch.cuda.get_device_name(0)}")
        print(f"   ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")

    # ===== ë°ì´í„° ë¡œë“œ =====
    print("ğŸ“š ë°ì´í„° ë¡œë”©...")
    texts, labels = load_data(JSON_PATH)
    print(f"ì´ ìƒ˜í”Œ ìˆ˜: {len(texts)}")

    # ë ˆì´ë¸” ë¶„í¬ í™•ì¸
    unique_labels, counts = np.unique(labels, return_counts=True)
    print("\në ˆì´ë¸” ë¶„í¬:")
    for label, count in zip(unique_labels, counts):
        print(f"  ë‚œì´ë„ {label+1}: {count}ê°œ ({count/len(labels)*100:.1f}%)")

    # Train/Validation/Test ë¶„í•  (70/15/15)
    # ë‚œì´ë„ 10ì´ 1ê°œë¿ì´ë¯€ë¡œ stratify ì œê±° ë˜ëŠ” ì¡°ê±´ë¶€ ì‚¬ìš©
    try:
        X_train, X_temp, y_train, y_temp = train_test_split(
            texts, labels, test_size=0.3, random_state=42, stratify=labels
        )
        X_val, X_test, y_val, y_test = train_test_split(
            X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp
        )
    except ValueError as e:
        print(f" Stratified split ì‹¤íŒ¨: {e}")
        print("   ì¼ë°˜ random splitìœ¼ë¡œ ì „í™˜...")
        X_train, X_temp, y_train, y_temp = train_test_split(
            texts, labels, test_size=0.3, random_state=42
        )
        X_val, X_test, y_val, y_test = train_test_split(
            X_temp, y_temp, test_size=0.5, random_state=42
        )

    print(f"\në°ì´í„° ë¶„í• :")
    print(f"  Train: {len(X_train)}")
    print(f"  Validation: {len(X_val)}")
    print(f"  Test: {len(X_test)}")

    # ===== í† í¬ë‚˜ì´ì € & ëª¨ë¸ ë¡œë“œ =====
    print("\n ëª¨ë¸ ë¡œë”©...")
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)

    # 10ê°œ í´ë˜ìŠ¤ (ë‚œì´ë„ 1-10)
    model = AutoModelForSequenceClassification.from_pretrained(
        MODEL_NAME,
        num_labels=10,
        problem_type="single_label_classification"
    )
    model.to(device)

    # ===== ë°ì´í„°ì…‹ ìƒì„± =====
    train_dataset = TextDifficultyDataset(X_train, y_train, tokenizer, MAX_LENGTH)
    val_dataset = TextDifficultyDataset(X_val, y_val, tokenizer, MAX_LENGTH)
    test_dataset = TextDifficultyDataset(X_test, y_test, tokenizer, MAX_LENGTH)

    # ===== í•™ìŠµ ì„¤ì • =====
    # transformers ë²„ì „ í˜¸í™˜ì„±ì„ ìœ„í•œ ì„¤ì •
    try:
        # ìƒˆ ë²„ì „ (4.20+)
        training_args = TrainingArguments(
            output_dir=OUTPUT_DIR,
            num_train_epochs=NUM_EPOCHS,
            per_device_train_batch_size=BATCH_SIZE,
            per_device_eval_batch_size=BATCH_SIZE,
            warmup_steps=WARMUP_STEPS,
            learning_rate=LEARNING_RATE,
            logging_dir='./logs',
            logging_steps=50,
            eval_strategy="steps",  # ìƒˆ ë²„ì „
            eval_steps=100,
            save_strategy="steps",
            save_steps=500,
            load_best_model_at_end=True,
            metric_for_best_model="f1",
            greater_is_better=True,
            save_total_limit=3,
            fp16=torch.cuda.is_available(),
            dataloader_num_workers=2,
            remove_unused_columns=False,
        )
    except TypeError:
        # êµ¬ ë²„ì „ (4.19 ì´í•˜)
        print("âš ï¸ êµ¬ë²„ì „ transformers ê°ì§€, í˜¸í™˜ ëª¨ë“œ ì‚¬ìš©")
        training_args = TrainingArguments(
            output_dir=OUTPUT_DIR,
            num_train_epochs=NUM_EPOCHS,
            per_device_train_batch_size=BATCH_SIZE,
            per_device_eval_batch_size=BATCH_SIZE,
            warmup_steps=WARMUP_STEPS,
            learning_rate=LEARNING_RATE,
            logging_dir='./logs',
            logging_steps=50,
            evaluation_strategy="steps",  # êµ¬ ë²„ì „
            eval_steps=100,
            save_strategy="steps",
            save_steps=500,
            load_best_model_at_end=True,
            metric_for_best_model="f1",
            greater_is_better=True,
            save_total_limit=3,
            fp16=torch.cuda.is_available(),
            dataloader_num_workers=2,
            remove_unused_columns=False,
        )

    # ===== í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° (ë¶ˆê· í˜• í•´ê²°) =====
    label_counts = Counter(y_train)
    print(f"\ní•™ìŠµ ë°ì´í„° í´ë˜ìŠ¤ ë¶„í¬:")
    for label in range(10):
        count = label_counts.get(label, 0)
        if count > 0:
            print(f"  ë‚œì´ë„ {label+1}: {count}ê°œ ({count/len(y_train)*100:.1f}%)")
        else:
            print(f"  ë‚œì´ë„ {label+1}: 0ê°œ ")

    # í•™ìŠµ ë°ì´í„°ì— ìˆëŠ” í´ë˜ìŠ¤ë§Œìœ¼ë¡œ ê°€ì¤‘ì¹˜ ê³„ì‚°
    unique_train_labels = np.unique(y_train)
    if len(unique_train_labels) < 10:
        print(f"   ì¡´ì¬í•˜ëŠ” í´ë˜ìŠ¤: {[l+1 for l in unique_train_labels]}")

        # ë‚œì´ë„ 10ì´ ì—†ì„ ê°€ëŠ¥ì„±ì´ ë†’ìœ¼ë¯€ë¡œ, 9ì™€ ë³‘í•© ì œì•ˆ
        if 9 not in unique_train_labels:  # label 9 = difficulty 10
            print("\n ì œì•ˆ: ë‚œì´ë„ 10 ìƒ˜í”Œì´ ë„ˆë¬´ ì ìŒ.")
            print("   1. ë” ë§ì€ ë°ì´í„° ìˆ˜ì§‘")
            print("   2. ë‚œì´ë„ 9ì™€ 10ì„ í•˜ë‚˜ë¡œ ë³‘í•©")
            print("   3. ë‚œì´ë„ 10 ìƒ˜í”Œì„ ë³µì œ(oversampling)")

    # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
    class_weights = None
    try:
        # ëª¨ë“  í´ë˜ìŠ¤(0-9)ì— ëŒ€í•œ ê°€ì¤‘ì¹˜ ê³„ì‚°
        # ì—†ëŠ” í´ë˜ìŠ¤ëŠ” 1.0ìœ¼ë¡œ ì„¤ì •
        weights = np.ones(10)
        if len(unique_train_labels) > 0:
            calculated_weights = compute_class_weight(
                'balanced',
                classes=unique_train_labels,
                y=y_train
            )
            for i, label in enumerate(unique_train_labels):
                weights[label] = calculated_weights[i]

        # ê·¹ë‹¨ì ì¸ ê°€ì¤‘ì¹˜ ì œí•œ (ìµœëŒ€ 10ë°°ê¹Œì§€ë§Œ)
        max_weight = 10.0
        weights = np.clip(weights, 0.1, max_weight)

        class_weights = torch.tensor(weights, dtype=torch.float)
        print(f"\ní´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš© (ìµœëŒ€ {max_weight}ë°° ì œí•œ):")
        for i in range(10):
            if label_counts.get(i, 0) > 0:
                print(f"  ë‚œì´ë„ {i+1}: {weights[i]:.2f} (ìƒ˜í”Œ: {label_counts.get(i, 0)}ê°œ)")
    except Exception as e:
        print(f"\n í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
        print("   ê¸°ë³¸ ê°€ì¤‘ì¹˜(1.0) ì‚¬ìš©")

    class WeightedTrainer(Trainer):
        def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):
            labels = inputs.pop("labels")
            outputs = model(**inputs)
            logits = outputs.get('logits')

            # ê°€ì¤‘ì¹˜ ì ìš© ì†ì‹¤ í•¨ìˆ˜
            if class_weights is not None:
                loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights.to(logits.device))
            else:
                loss_fct = torch.nn.CrossEntropyLoss()

            loss = loss_fct(logits.view(-1, 10), labels.view(-1))
            return (loss, outputs) if return_outputs else loss

    # ===== Trainer ìƒì„± =====
    trainer = WeightedTrainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=val_dataset,
        tokenizer=tokenizer,
        compute_metrics=compute_metrics,
        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]
    )

    # ===== í•™ìŠµ =====
    print("\n í•™ìŠµ ì‹œì‘...")
    trainer.train()

    # ===== í‰ê°€ =====
    print("\n í…ŒìŠ¤íŠ¸ì…‹ í‰ê°€...")
    test_results = trainer.evaluate(test_dataset)

    print("\ní…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    for key, value in test_results.items():
        if key.startswith('eval_'):
            metric_name = key.replace('eval_', '')
            print(f"  {metric_name}: {value:.4f}")

    # ===== ì˜ˆì¸¡ & í˜¼ë™í–‰ë ¬ =====
    print("\nğŸ” ìƒì„¸ ë¶„ì„...")
    predictions = trainer.predict(test_dataset)
    y_pred = np.argmax(predictions.predictions, axis=1)

    # í˜¼ë™ í–‰ë ¬ ê·¸ë¦¬ê¸°
    plot_confusion_matrix(y_test, y_pred, save_path=f"{OUTPUT_DIR}/confusion_matrix.png")

    # ===== ëª¨ë¸ ì €ì¥ =====
    print(f"\nğŸ’¾ ëª¨ë¸ ì €ì¥: {OUTPUT_DIR}")
    trainer.save_model(OUTPUT_DIR)
    tokenizer.save_pretrained(OUTPUT_DIR)

    # ===== ìƒ˜í”Œ ì˜ˆì¸¡ =====
    print("\n ìƒ˜í”Œ ì˜ˆì¸¡:")
    sample_texts = [
        "ì€í–‰ì— ëˆì„ ë§¡ê²¨ìš”",
        "ì˜ˆê¸ˆìë³´í˜¸ë²•ì— ë”°ë¼ 5ì²œë§Œì›ê¹Œì§€ ë³´í˜¸ë©ë‹ˆë‹¤",
        "ì‹ ìš©íŒŒìƒê²°í•©ì¦ê¶Œì˜ CDS ìŠ¤í”„ë ˆë“œ ë³€ë™ì— ë”°ë¥¸ ìˆ˜ìµêµ¬ì¡°"
    ]

    for text in sample_texts:
        inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=MAX_LENGTH)
        inputs = {k: v.to(device) for k, v in inputs.items()}

        with torch.no_grad():
            outputs = model(**inputs)
            prediction = torch.argmax(outputs.logits, dim=-1).item()

        print(f"  í…ìŠ¤íŠ¸: {text[:50]}...")
        print(f"  ì˜ˆì¸¡ ë‚œì´ë„: {prediction + 1}")

    # ===== ë©”íƒ€ë°ì´í„° ì €ì¥ =====
    metadata = {
        'model_name': MODEL_NAME,
        'num_classes': 10,
        'max_length': MAX_LENGTH,
        'training_samples': len(X_train),
        'validation_samples': len(X_val),
        'test_samples': len(X_test),
        'test_accuracy': test_results.get('eval_accuracy', 0),
        'test_f1': test_results.get('eval_f1', 0),
        'test_mae': test_results.get('eval_mae', 0),
        'test_within_1_acc': test_results.get('eval_within_1_acc', 0),
        'json_path': JSON_PATH,
        'output_dir': OUTPUT_DIR,
        'device': str(device),
        'is_colab': is_colab
    }

    metadata_path = os.path.join(OUTPUT_DIR, "training_metadata.json")
    with open(metadata_path, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)
    print(f"\n ë©”íƒ€ë°ì´í„° ì €ì¥: {metadata_path}")

    print("\n Fine-tuning ì™„ë£Œ!")
    print(f" ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {OUTPUT_DIR}")

    if is_colab:
        print("\nğŸ’¡ Colabì—ì„œ ëª¨ë¸ ì‚¬ìš©í•˜ê¸°:")
        print(f"   from transformers import AutoTokenizer, AutoModelForSequenceClassification")
        print(f"   model = AutoModelForSequenceClassification.from_pretrained('{OUTPUT_DIR}')")
        print(f"   tokenizer = AutoTokenizer.from_pretrained('{OUTPUT_DIR}')")

    return model, tokenizer

# ===== ì¶”ë¡ ìš© í•¨ìˆ˜ =====
def predict_difficulty(text, model, tokenizer, device='cpu'):
    """ë‹¨ì¼ í…ìŠ¤íŠ¸ ë‚œì´ë„ ì˜ˆì¸¡"""
    model.eval()
    model.to(device)

    inputs = tokenizer(
        text,
        return_tensors="pt",
        truncation=True,
        max_length=512,
        padding=True
    )
    inputs = {k: v.to(device) for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        probabilities = torch.softmax(logits, dim=-1)
        prediction = torch.argmax(logits, dim=-1).item()

    return {
        'difficulty': prediction + 1,  # 1-10 ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
        'confidence': probabilities[0][prediction].item(),
        'probabilities': probabilities[0].cpu().numpy()
    }

# ===== ë°°ì¹˜ ì¶”ë¡  =====
def predict_batch(texts, model, tokenizer, batch_size=32, device='cpu'):
    """ì—¬ëŸ¬ í…ìŠ¤íŠ¸ ë°°ì¹˜ ì²˜ë¦¬"""
    model.eval()
    model.to(device)

    results = []

    for i in tqdm(range(0, len(texts), batch_size), desc="ë°°ì¹˜ ì¶”ë¡ "):
        batch_texts = texts[i:i+batch_size]

        inputs = tokenizer(
            batch_texts,
            return_tensors="pt",
            truncation=True,
            max_length=512,
            padding=True
        )
        inputs = {k: v.to(device) for k, v in inputs.items()}

        with torch.no_grad():
            outputs = model(**inputs)
            logits = outputs.logits
            predictions = torch.argmax(logits, dim=-1)

            for j, pred in enumerate(predictions):
                results.append({
                    'text': batch_texts[j],
                    'difficulty': pred.item() + 1
                })

    return results

if __name__ == "__main__":
    model, tokenizer = main()