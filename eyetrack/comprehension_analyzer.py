import numpy as np
from dataclasses import dataclass
from typing import List, Dict, Tuple
import time
from collections import defaultdict

@dataclass
class ComprehensionMetrics:
    difficulty_score: float  # 0-1, ë†’ì„ìˆ˜ë¡ ì–´ë ¤ì›€
    understanding_level: str  # 'high', 'medium', 'low'
    problem_areas: List[str]  # ì´í•´ ì–´ë ¤ìš´ ë¶€ë¶„ë“¤
    reading_efficiency: float  # WPM adjusted for comprehension
    cognitive_load: float  # ì¸ì§€ ë¶€í•˜ ìˆ˜ì¤€

class ComprehensionAnalyzer:
    def __init__(self):
        self.word_fixations = defaultdict(list)  # ë‹¨ì–´ë³„ ì‘ì‹œ ì‹œê°„
        self.sentence_metrics = defaultdict(dict)  # ë¬¸ì¥ë³„ ë©”íŠ¸ë¦­
        self.regression_map = []  # íšŒê·€ íŒ¨í„´
        self.reading_speed_variations = []
        
        # ì„ê³„ê°’ ì„¤ì •
        self.DIFFICULT_FIXATION_THRESHOLD = 500  # ms
        self.EASY_FIXATION_THRESHOLD = 200  # ms
        self.REGRESSION_THRESHOLD = 3  # íšŒê·€ íšŸìˆ˜
        
    def analyze_fixation_pattern(self, word: str, fixation_duration: float, 
                                position: Tuple[int, int]):
        """ë‹¨ì–´ë³„ ì‘ì‹œ íŒ¨í„´ ë¶„ì„"""
        self.word_fixations[word].append({
            'duration': fixation_duration,
            'position': position,
            'timestamp': time.time()
        })
        
        # ë‚œì´ë„ ê³„ì‚°
        avg_duration = np.mean([f['duration'] for f in self.word_fixations[word]])
        
        if avg_duration > self.DIFFICULT_FIXATION_THRESHOLD:
            return 'difficult'
        elif avg_duration < self.EASY_FIXATION_THRESHOLD:
            return 'easy'
        else:
            return 'moderate'
    
    def detect_comprehension_issues(self, sentence: str, metrics: Dict) -> Dict:
        """ë¬¸ì¥ ë‹¨ìœ„ ì´í•´ë„ ë¬¸ì œ ê°ì§€"""
        issues = {
            'has_difficulty': False,
            'difficulty_type': [],
            'suggestions': []
        }
        
        # 1. ê¸´ ì‘ì‹œ ì‹œê°„ ì²´í¬
        if metrics.get('avg_fixation', 0) > self.DIFFICULT_FIXATION_THRESHOLD:
            issues['has_difficulty'] = True
            issues['difficulty_type'].append('complex_content')
            issues['suggestions'].append('ì´ ë¶€ë¶„ì€ ì²œì²œíˆ ë‹¤ì‹œ ì½ì–´ë³´ì„¸ìš”')
        
        # 2. ë†’ì€ íšŒê·€ìœ¨ ì²´í¬
        if metrics.get('regression_count', 0) > self.REGRESSION_THRESHOLD:
            issues['has_difficulty'] = True
            issues['difficulty_type'].append('confusion')
            issues['suggestions'].append('ì• ë¬¸ì¥ê³¼ì˜ ì—°ê´€ì„±ì„ í™•ì¸í•˜ì„¸ìš”')
        
        # 3. ë¶ˆê·œì¹™í•œ ì½ê¸° ì†ë„
        if metrics.get('speed_variance', 0) > 0.5:
            issues['has_difficulty'] = True
            issues['difficulty_type'].append('inconsistent_reading')
            issues['suggestions'].append('ì¼ì •í•œ ì†ë„ë¡œ ì½ê¸°ë¥¼ ì‹œë„í•˜ì„¸ìš”')
        
        return issues
    
    def calculate_cognitive_load(self, fixations: List, regressions: int, 
                                reading_speed: float) -> float:
        """ì¸ì§€ ë¶€í•˜ ê³„ì‚° (0-1)"""
        # ì‘ì‹œ ì‹œê°„ ë³€ë™ì„±
        if len(fixations) > 1:
            fixation_variance = np.std([f['duration'] for f in fixations]) / 1000
        else:
            fixation_variance = 0
        
        # íšŒê·€ ë¹ˆë„
        regression_factor = min(regressions / 10, 1.0)
        
        # ì½ê¸° ì†ë„ (ë„ˆë¬´ ë¹ ë¥´ê±°ë‚˜ ëŠë¦¬ë©´ ë¶€í•˜ ì¦ê°€)
        optimal_wpm = 250
        speed_factor = abs(reading_speed - optimal_wpm) / optimal_wpm
        
        # ì¢…í•© ì¸ì§€ ë¶€í•˜
        cognitive_load = (fixation_variance * 0.4 + 
                         regression_factor * 0.4 + 
                         speed_factor * 0.2)
        
        return min(cognitive_load, 1.0)
    
    def generate_comprehension_report(self, reading_session_data: Dict) -> ComprehensionMetrics:
        """ì¢…í•© ì´í•´ë„ ë¦¬í¬íŠ¸ ìƒì„±"""
        
        # ì „ì²´ ë‚œì´ë„ ì ìˆ˜ ê³„ì‚°
        all_fixations = []
        for word_data in self.word_fixations.values():
            all_fixations.extend([f['duration'] for f in word_data])
        
        if all_fixations:
            avg_fixation = np.mean(all_fixations)
            difficulty_score = min(avg_fixation / 1000, 1.0)  # ì •ê·œí™”
        else:
            difficulty_score = 0.5
        
        # ì´í•´ë„ ìˆ˜ì¤€ íŒì •
        if difficulty_score < 0.3:
            understanding_level = 'high'
        elif difficulty_score < 0.6:
            understanding_level = 'medium'
        else:
            understanding_level = 'low'
        
        # ë¬¸ì œ ì˜ì—­ ì‹ë³„
        problem_areas = []
        for word, fixations in self.word_fixations.items():
            avg_duration = np.mean([f['duration'] for f in fixations])
            if avg_duration > self.DIFFICULT_FIXATION_THRESHOLD:
                problem_areas.append(word)
        
        # ì½ê¸° íš¨ìœ¨ì„± (ì´í•´ë„ ì¡°ì •ëœ WPM)
        base_wpm = reading_session_data.get('wpm', 200)
        efficiency = base_wpm * (1 - difficulty_score * 0.5)
        
        # ì¸ì§€ ë¶€í•˜
        cognitive_load = self.calculate_cognitive_load(
            all_fixations,
            len(self.regression_map),
            base_wpm
        )
        
        return ComprehensionMetrics(
            difficulty_score=difficulty_score,
            understanding_level=understanding_level,
            problem_areas=problem_areas[:5],  # ìƒìœ„ 5ê°œë§Œ
            reading_efficiency=efficiency,
            cognitive_load=cognitive_load
        )
    
    def suggest_improvements(self, metrics: ComprehensionMetrics) -> List[str]:
        """ê°œì„  ì œì•ˆ ìƒì„±"""
        suggestions = []
        
        if metrics.difficulty_score > 0.6:
            suggestions.append("ğŸ“š ì´ í…ìŠ¤íŠ¸ëŠ” ë‚œì´ë„ê°€ ë†’ìŠµë‹ˆë‹¤. í•µì‹¬ ìš©ì–´ë¥¼ ë¨¼ì € ì´í•´í•˜ì„¸ìš”.")
        
        if metrics.cognitive_load > 0.7:
            suggestions.append("ğŸ§  ì¸ì§€ ë¶€í•˜ê°€ ë†’ìŠµë‹ˆë‹¤. ì ì‹œ íœ´ì‹ í›„ ë‹¤ì‹œ ì½ì–´ë³´ì„¸ìš”.")
        
        if len(metrics.problem_areas) > 0:
            suggestions.append(f"âš ï¸ ì–´ë ¤ìš´ ë¶€ë¶„: {', '.join(metrics.problem_areas[:3])}")
        
        if metrics.reading_efficiency < 150:
            suggestions.append("ğŸŒ ì½ê¸° ì†ë„ê°€ ëŠë¦½ë‹ˆë‹¤. ë‹¨ë½ë³„ë¡œ ìš”ì•½í•˜ë©° ì½ì–´ë³´ì„¸ìš”.")
        
        return suggestions

# ì‹¤ì‹œê°„ ì´í•´ë„ ëª¨ë‹ˆí„°ë§
class RealTimeComprehensionMonitor:
    def __init__(self):
        self.analyzer = ComprehensionAnalyzer()
        self.current_paragraph = ""
        self.paragraph_start_time = None
        
    def process_gaze_event(self, gaze_x: int, gaze_y: int, 
                          text_at_gaze: str, timestamp: float):
        """ì‹¤ì‹œê°„ ì‹œì„  ì´ë²¤íŠ¸ ì²˜ë¦¬"""
        
        # í˜„ì¬ ë³´ê³  ìˆëŠ” í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´
        if text_at_gaze:
            # ì‘ì‹œ ì‹œê°„ ê³„ì‚°
            if hasattr(self, 'last_word') and self.last_word == text_at_gaze:
                fixation_duration = (timestamp - self.last_timestamp) * 1000
                difficulty = self.analyzer.analyze_fixation_pattern(
                    text_at_gaze, fixation_duration, (gaze_x, gaze_y)
                )
                
                # ì‹¤ì‹œê°„ í”¼ë“œë°±
                if difficulty == 'difficult':
                    return f"âš ï¸ '{text_at_gaze}' - ì´í•´ê°€ ì–´ë ¤ìš°ì‹ ê°€ìš”?"
                
            self.last_word = text_at_gaze
            self.last_timestamp = timestamp
        
        return None
    
    def get_realtime_feedback(self) -> Dict:
        """ì‹¤ì‹œê°„ í”¼ë“œë°± ìƒì„±"""
        recent_fixations = []
        for word_data in self.analyzer.word_fixations.values():
            if word_data:
                recent_fixations.extend(word_data[-5:])  # ìµœê·¼ 5ê°œ
        
        if recent_fixations:
            avg_recent = np.mean([f['duration'] for f in recent_fixations])
            
            if avg_recent > 600:
                return {
                    'status': 'struggling',
                    'message': 'ì§‘ì¤‘ë ¥ì´ ë–¨ì–´ì§€ê³  ìˆë‚˜ìš”? ì ì‹œ íœ´ì‹ì„ ì·¨í•˜ì„¸ìš”.',
                    'color': (255, 100, 100)
                }
            elif avg_recent < 200:
                return {
                    'status': 'skimming',
                    'message': 'ë„ˆë¬´ ë¹¨ë¦¬ ì½ê³  ìˆìŠµë‹ˆë‹¤. ë‚´ìš©ì„ ì´í•´í•˜ë©° ì½ìœ¼ì„¸ìš”.',
                    'color': (255, 255, 100)
                }
            else:
                return {
                    'status': 'good',
                    'message': 'ì¢‹ì€ ì†ë„ë¡œ ì½ê³  ìˆìŠµë‹ˆë‹¤!',
                    'color': (100, 255, 100)
                }
        
        return {
            'status': 'starting',
            'message': 'ì½ê¸°ë¥¼ ì‹œì‘í•˜ì„¸ìš”...',
            'color': (200, 200, 200)
        }