"""
ì‹¤ì‹œê°„ Confusion Binary ì¶”ì ê¸° - HuggingFace ë²„ì „
Confusion ì´ì§„ ë¶„ë¥˜ ëª¨ë¸ ì‚¬ìš© (Confused vs Not Confused)
"""

import cv2
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
import numpy as np
from collections import deque
import time
import os
import mediapipe as mp
from huggingface_hub import hf_hub_download

# GPU ì„¤ì •
if torch.cuda.is_available():
    device = torch.device("cuda")
elif torch.backends.mps.is_available():
    device = torch.device("mps")
else:
    device = torch.device("cpu")
print(f"Using device: {device}")


class RealtimeConfusionTrackerHF:
    """ì‹¤ì‹œê°„ Confusion ì´ì§„ ë¶„ë¥˜ ì¶”ì ê¸°"""
    
    def __init__(self, 
                 repo_id='combe4259/face-comprehension',
                 sequence_length=30, 
                 buffer_size=30,
                 prediction_interval=0.5,
                 cache_dir='./model_cache'):
        """
        Args:
            repo_id: HuggingFace ëª¨ë¸ ë ˆí¬ì§€í† ë¦¬ ID
            sequence_length: ëª¨ë¸ì— ì…ë ¥í•  í”„ë ˆì„ ìˆ˜
            buffer_size: ë²„í¼ í¬ê¸°
            prediction_interval: ì˜ˆì¸¡ ì£¼ê¸° (ì´ˆ)
            cache_dir: ëª¨ë¸ ìºì‹œ ë””ë ‰í† ë¦¬
        """
        self.sequence_length = sequence_length
        self.buffer_size = buffer_size
        self.prediction_interval = prediction_interval
        self.repo_id = repo_id
        
        # í”„ë ˆì„ ë²„í¼
        self.frame_buffer = deque(maxlen=buffer_size)
        
        # HuggingFaceì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ
        print(f"ğŸ“¥ Downloading Confusion Binary model from: {repo_id}")
        try:
            # ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
            model_path = hf_hub_download(
                repo_id=repo_id,
                filename="pytorch_model.bin",
                cache_dir=cache_dir
            )
            print(f"âœ… Model downloaded to: {model_path}")
            
            # ëª¨ë¸ ë¡œë“œ (ì „ì²´ ëª¨ë¸ì´ ì €ì¥ëœ ê²½ìš°)
            print("Loading Confusion Binary model...")
            self.model = torch.load(model_path, map_location=device)
            self.model.to(device)
            self.model.eval()
            print("âœ… Confusion Binary model loaded successfully")
            
        except Exception as e:
            print(f"âŒ Failed to load model: {e}")
            raise e
        
        # ì „ì²˜ë¦¬ ë³€í™˜
        self.transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((112, 112)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                              std=[0.229, 0.224, 0.225])
        ])
        
        # MediaPipe ì–¼êµ´ ê°ì§€
        self.mp_face_detection = mp.solutions.face_detection
        self.mp_face_mesh = mp.solutions.face_mesh
        self.mp_drawing = mp.solutions.drawing_utils
        
        self.face_detection = self.mp_face_detection.FaceDetection(
            min_detection_confidence=0.5
        )
        
        # Face Mesh (ì˜µì…˜)
        self.face_mesh = self.mp_face_mesh.FaceMesh(
            max_num_faces=1,
            refine_landmarks=True,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )
        
        # ìƒíƒœ ë³€ìˆ˜
        self.last_prediction_time = 0
        self.current_confusion_state = "Unknown"
        self.confusion_probability = 0.0
        
        # ìƒ‰ìƒ ì •ì˜
        self.color_not_confused = (0, 255, 0)  # ì´ˆë¡ìƒ‰
        self.color_confused = (0, 0, 255)  # ë¹¨ê°„ìƒ‰
        self.color_neutral = (255, 255, 0)  # ë…¸ë€ìƒ‰
    
    def predict_confusion(self, frames):
        """Confusion ìƒíƒœ ì˜ˆì¸¡ (ì´ì§„ ë¶„ë¥˜)"""
        if len(frames) < self.sequence_length:
            return None
        
        # í”„ë ˆì„ ì¤€ë¹„
        processed_frames = []
        for frame in frames[-self.sequence_length:]:
            processed = self.transform(frame)
            processed_frames.append(processed)
        
        # ë°°ì¹˜ ìƒì„±
        batch = torch.stack(processed_frames).unsqueeze(0).to(device)
        
        # ì˜ˆì¸¡
        with torch.no_grad():
            outputs = self.model(batch)
            probabilities = F.softmax(outputs, dim=1)
            
            # í´ë˜ìŠ¤ 0: Not Confused, í´ë˜ìŠ¤ 1: Confused
            not_confused_prob = probabilities[0, 0].item()
            confused_prob = probabilities[0, 1].item()
            
            # ì˜ˆì¸¡ í´ë˜ìŠ¤
            predicted_class = torch.argmax(probabilities, dim=1).item()
        
        # ê²°ê³¼ ì €ì¥
        result = {
            'confused': predicted_class == 1,
            'probability': confused_prob,
            'not_confused_probability': not_confused_prob,
            'state': 'Confused' if predicted_class == 1 else 'Not Confused'
        }
        
        return result
    
    def process_frame(self, frame):
        """í”„ë ˆì„ ì²˜ë¦¬ ë° ì˜ˆì¸¡"""
        current_time = time.time()
        
        # ì–¼êµ´ ê°ì§€
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = self.face_detection.process(frame_rgb)
        
        if results.detections:
            for detection in results.detections:
                # ë°”ìš´ë”© ë°•ìŠ¤ ê°€ì ¸ì˜¤ê¸°
                bbox = detection.location_data.relative_bounding_box
                h, w, _ = frame.shape
                x = int(bbox.xmin * w)
                y = int(bbox.ymin * h)
                width = int(bbox.width * w)
                height = int(bbox.height * h)
                
                # ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ
                face_roi = frame[max(0, y):min(h, y+height), 
                                max(0, x):min(w, x+width)]
                
                if face_roi.size > 0:
                    # ë²„í¼ì— ì¶”ê°€
                    face_rgb = cv2.cvtColor(face_roi, cv2.COLOR_BGR2RGB)
                    self.frame_buffer.append(face_rgb)
                    
                    # ì˜ˆì¸¡ (ì£¼ê¸°ì ìœ¼ë¡œ)
                    if current_time - self.last_prediction_time > self.prediction_interval:
                        if len(self.frame_buffer) >= self.sequence_length:
                            prediction = self.predict_confusion(list(self.frame_buffer))
                            if prediction:
                                self.current_confusion_state = prediction['state']
                                self.confusion_probability = prediction['probability']
                                self.last_prediction_time = current_time
                
                # ì‹œê°í™”
                self.visualize_results(frame, x, y, width, height)
        
        return frame
    
    def visualize_results(self, frame, x, y, width, height):
        """ê²°ê³¼ ì‹œê°í™”"""
        # ìƒ‰ìƒ ê²°ì •
        if self.current_confusion_state == "Confused":
            box_color = self.color_confused
        elif self.current_confusion_state == "Not Confused":
            box_color = self.color_not_confused
        else:
            box_color = self.color_neutral
        
        # ë°”ìš´ë”© ë°•ìŠ¤
        cv2.rectangle(frame, (x, y), (x+width, y+height), box_color, 2)
        
        # ìƒíƒœ í…ìŠ¤íŠ¸
        status_text = f"{self.current_confusion_state}"
        prob_text = f"Confusion: {self.confusion_probability:.1%}"
        
        # ë°°ê²½ ë°•ìŠ¤
        cv2.rectangle(frame, (x, y-50), (x+300, y), (0, 0, 0), -1)
        
        # í…ìŠ¤íŠ¸
        cv2.putText(frame, status_text, (x+5, y-30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, box_color, 2)
        cv2.putText(frame, prob_text, (x+5, y-10),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
        
        # í”„ë¡œê·¸ë ˆìŠ¤ ë°”
        bar_width = 200
        bar_height = 10
        bar_x = x
        bar_y = y + height + 10
        
        # ë°°ê²½
        cv2.rectangle(frame, (bar_x, bar_y), 
                     (bar_x + bar_width, bar_y + bar_height), 
                     (100, 100, 100), -1)
        
        # Confusion ë ˆë²¨
        fill_width = int(bar_width * self.confusion_probability)
        cv2.rectangle(frame, (bar_x, bar_y), 
                     (bar_x + fill_width, bar_y + bar_height), 
                     box_color, -1)
    
    def run(self):
        """ì‹¤ì‹œê°„ ì¶”ì  ì‹¤í–‰"""
        print("\nğŸ¥ Starting Confusion Tracker...")
        print("Press 'q' to quit, 'r' to reset")
        print("-" * 50)
        
        cap = cv2.VideoCapture(0)
        
        # ì¹´ë©”ë¼ ì„¤ì •
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        cap.set(cv2.CAP_PROP_FPS, 30)
        
        fps_counter = 0
        fps_time = time.time()
        fps = 0
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            # í”„ë ˆì„ ì²˜ë¦¬
            frame = self.process_frame(frame)
            
            # FPS ê³„ì‚°
            fps_counter += 1
            if time.time() - fps_time > 1.0:
                fps = fps_counter
                fps_counter = 0
                fps_time = time.time()
            
            # FPS í‘œì‹œ
            cv2.putText(frame, f"FPS: {fps}", (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 1)
            
            # ëª¨ë¸ ì •ë³´ í‘œì‹œ
            cv2.putText(frame, f"Model: Confusion Binary", (10, 60),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)
            
            # í™”ë©´ í‘œì‹œ
            cv2.imshow('Confusion Tracker', frame)
            
            # í‚¤ ì…ë ¥ ì²˜ë¦¬
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            elif key == ord('r'):
                self.current_confusion_state = "Unknown"
                self.confusion_probability = 0.0
                print("Reset confusion state")
        
        cap.release()
        cv2.destroyAllWindows()
        print("\nâœ… Confusion Tracker stopped")


if __name__ == "__main__":
    # ì‹¤í–‰
    tracker = RealtimeConfusionTrackerHF(
        repo_id='combe4259/face-comprehension',  # HuggingFace ë ˆí¬ì§€í† ë¦¬
        sequence_length=30,
        buffer_size=30,
        prediction_interval=0.5  # 0.5ì´ˆë§ˆë‹¤ ì˜ˆì¸¡
    )
    tracker.run()