import React, { useRef, useEffect, useState } from 'react';
import './WebcamFaceDetection.css';

interface FaceDetectionData {
  hasDetection: boolean;
  confidence: number;
  emotions?: {
    engagement: number;
    confusion: number;
    frustration: number;
    boredom: number;
  };
}

interface WebcamFaceDetectionProps {
  onFaceAnalysis: (data: FaceDetectionData) => void;
  isActive: boolean;
  useExistingStream?: boolean;  // ê¸°ì¡´ ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ ì‚¬ìš© ì—¬ë¶€
}

const WebcamFaceDetection: React.FC<WebcamFaceDetectionProps> = ({
  onFaceAnalysis,
  isActive,
  useExistingStream = false
}) => {
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const [stream, setStream] = useState<MediaStream | null>(null);
  const [isWebcamActive, setIsWebcamActive] = useState(false);
  const [error, setError] = useState<string>('');
  const [faceDetected, setFaceDetected] = useState(false);
  const [isMockMode, setIsMockMode] = useState(false);
  
  // CNN-LSTMì„ ìœ„í•œ í”„ë ˆì„ ë²„í¼ (30í”„ë ˆì„ ì‹œí€€ìŠ¤)
  const frameBufferRef = useRef<ImageData[]>([]);
  const frameBufferSize = 30; // CNN-LSTM sequence length
  const frameInterval = 200; // 200msë§ˆë‹¤ í”„ë ˆì„ ìº¡ì²˜ (5fps, 6ì´ˆê°„ ìˆ˜ì§‘)

  // ì›¹ìº  ì‹œì‘
  const startWebcam = async () => {
    console.log('ğŸ¥ ì›¹ìº  ì‹œì‘ ì‹œë„...');
    try {
      // ë¸Œë¼ìš°ì € ì§€ì› í™•ì¸
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        console.error('âŒ ë¸Œë¼ìš°ì €ê°€ ì›¹ìº ì„ ì§€ì›í•˜ì§€ ì•ŠìŒ');
        throw new Error('ë¸Œë¼ìš°ì €ê°€ ì›¹ìº ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤');
      }

      // ì›¹ìº  ì ‘ê·¼ì— íƒ€ì„ì•„ì›ƒ ì¶”ê°€ (15ì´ˆë¡œ ì—°ì¥)
      const mediaStreamPromise = navigator.mediaDevices.getUserMedia({
        video: {
          width: { ideal: 640, min: 320 },
          height: { ideal: 480, min: 240 },
          facingMode: 'user'
        },
        audio: false
      });

      const timeoutPromise = new Promise<never>((_, reject) => {
        setTimeout(() => reject(new Error('ì›¹ìº  ì ‘ê·¼ ì‹œê°„ ì´ˆê³¼')), 15000);
      });

      const mediaStream = await Promise.race([mediaStreamPromise, timeoutPromise]);

      if (videoRef.current) {
        videoRef.current.srcObject = mediaStream;
        setStream(mediaStream);
        setIsWebcamActive(true);
        setError('');
        console.log('âœ… ì›¹ìº  ì—°ê²° ì„±ê³µ!');
      }
    } catch (err: any) {
      console.error('ì›¹ìº  ì ‘ê·¼ ì‹¤íŒ¨:', err);
      let errorMessage = '';

      switch (err.name) {
        case 'NotAllowedError':
          errorMessage = 'ì›¹ìº  ì ‘ê·¼ì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì£¼ì†Œì°½ì˜ ì¹´ë©”ë¼ ì•„ì´ì½˜ì„ í´ë¦­í•˜ì—¬ í—ˆìš©í•´ì£¼ì„¸ìš”.';
          break;
        case 'NotFoundError':
          errorMessage = 'ì›¹ìº ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¹´ë©”ë¼ê°€ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.';
          break;
        case 'NotReadableError':
          errorMessage = 'ì›¹ìº ì´ ë‹¤ë¥¸ ì•±ì—ì„œ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤. ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.';
          break;
        case 'OverconstrainedError':
          errorMessage = 'ì›¹ìº  ì„¤ì •ì´ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì¹´ë©”ë¼ ë“œë¼ì´ë²„ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.';
          break;
        default:
          if (err.message === 'ì›¹ìº  ì ‘ê·¼ ì‹œê°„ ì´ˆê³¼') {
            errorMessage = 'ì›¹ìº  ì—°ê²°ì´ ì§€ì—°ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.';
          } else if (err.message === 'ë¸Œë¼ìš°ì €ê°€ ì›¹ìº ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤') {
            errorMessage = 'ë¸Œë¼ìš°ì €ê°€ ì›¹ìº ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. Chrome, Firefox, Edgeë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.';
          } else {
            errorMessage = 'ì›¹ìº  ì ‘ê·¼ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.';
          }
      }

      setError(errorMessage);

      // ì›¹ìº  ì‹¤íŒ¨ ì‹œ ëª©ì—…ë°ì´í„°ë¡œ í´ë°±
      startMockDataFallback();
    }
  };

  // ëª©ì—…ë°ì´í„° í´ë°± ì‹œì‘ - ì œê±°
  const startMockDataFallback = () => {
    setIsMockMode(true);
    setIsWebcamActive(false);
    setError('ì›¹ìº  ì—°ê²° ì‹¤íŒ¨ - í”„ë ˆì„ ìˆ˜ì§‘ ëª¨ë“œë¡œ ì „í™˜');
    
    // ëª©ì—… ë°ì´í„° ëŒ€ì‹  í”„ë ˆì„ ë²„í¼ ì´ˆê¸°í™”ë§Œ
    console.log('ì›¹ìº  ì‹¤íŒ¨ - ì‹¤ì œ ì–¼êµ´ ë¶„ì„ì„ ìœ„í•œ í”„ë ˆì„ ë²„í¼ ì´ˆê¸°í™”');
  };

  // ì›¹ìº  ì¤‘ì§€
  const stopWebcam = () => {
    if (stream) {
      stream.getTracks().forEach(track => track.stop());
      setStream(null);
      setIsWebcamActive(false);
      setFaceDetected(false);
    }
  };

  // í”„ë ˆì„ ìº¡ì²˜ ë° ë¶„ì„
  const captureAndAnalyze = async () => {
    if (!videoRef.current || !canvasRef.current || !isWebcamActive) return;

    const video = videoRef.current;
    const canvas = canvasRef.current;
    const ctx = canvas.getContext('2d');

    if (!ctx) return;

    // ë¹„ë””ì˜¤ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ëŒ€ê¸°
    if (video.readyState < 2) return;

    // 112x112ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (CNN-LSTM ì…ë ¥ í¬ê¸°)
    canvas.width = 112;
    canvas.height = 112;
    ctx.drawImage(video, 0, 0, 112, 112);

    // í”„ë ˆì„ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    const imageData = ctx.getImageData(0, 0, 112, 112);
    
    // í”„ë ˆì„ ë²„í¼ì— ì¶”ê°€
    frameBufferRef.current.push(imageData);
    
    // ë²„í¼ í¬ê¸° ìœ ì§€ (ìµœëŒ€ 30í”„ë ˆì„)
    if (frameBufferRef.current.length > frameBufferSize) {
      frameBufferRef.current.shift();
    }
    
    // í”„ë ˆì„ ìˆ˜ì§‘ ìƒíƒœ ë¡œê¹… (ê°€ë”ì”©ë§Œ)
    if (frameBufferRef.current.length % 10 === 0) {
      console.log(`ğŸ“¹ í”„ë ˆì„ ìˆ˜ì§‘ ì¤‘: ${frameBufferRef.current.length}/${frameBufferSize}`);
    }

    // 30í”„ë ˆì„ì´ ëª¨ì´ë©´ ë°±ì—”ë“œë¡œ ì „ì†¡
    if (frameBufferRef.current.length === frameBufferSize) {
      console.log('ğŸ“¤ 30í”„ë ˆì„ ì‹œí€€ìŠ¤ ë°±ì—”ë“œ ì „ì†¡ ì‹œì‘...');
      await sendFramesToBackend();
    }

    // ê°„ë‹¨í•œ ì–¼êµ´ ê°ì§€ (í”½ì…€ ì²´í¬)
    const hasDetection = await simulateFaceDetection(canvas);
    setFaceDetected(hasDetection);
  };

  // í”„ë ˆì„ ì‹œí€€ìŠ¤ë¥¼ ë°±ì—”ë“œë¡œ ì „ì†¡
  const sendFramesToBackend = async () => {
    try {
      // í”„ë ˆì„ ë°ì´í„°ë¥¼ Base64ë¡œ ë³€í™˜
      const frames = frameBufferRef.current.map(imageData => {
        const canvas = document.createElement('canvas');
        canvas.width = 112;
        canvas.height = 112;
        const ctx = canvas.getContext('2d');
        if (ctx) {
          ctx.putImageData(imageData, 0, 0);
          return canvas.toDataURL('image/jpeg', 0.7).split(',')[1]; // Base64ë§Œ ì¶”ì¶œ
        }
        return '';
      }).filter(frame => frame !== '');

      // ë°±ì—”ë“œ AI ì„œë¹„ìŠ¤ í˜¸ì¶œ
      const response = await fetch('http://localhost:8000/api/face/analyze', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          frames: frames,
          sequence_length: frameBufferSize
        })
      });

      if (response.ok) {
        const result = await response.json();
        console.log('ğŸ§  CNN-LSTM ì–¼êµ´ ë¶„ì„ ê²°ê³¼:', {
          confusion: result.confusion_probability?.toFixed(2),
          timestamp: new Date().toLocaleTimeString()
        });
        
        // confusion ë ˆë²¨ë§Œ ì‚¬ìš© (0-3 -> 0-1 ì •ê·œí™”)
        const confusionLevel = result.confusion || 0;
        const normalizedConfusion = confusionLevel / 3.0; // 0-3ì„ 0-1ë¡œ ì •ê·œí™”
        
        const faceData: FaceDetectionData = {
          hasDetection: true,
          confidence: result.confidence || 0.9,
          emotions: {
            engagement: 0, // ì‚¬ìš© ì•ˆ í•¨
            confusion: normalizedConfusion,
            frustration: 0, // ì‚¬ìš© ì•ˆ í•¨
            boredom: 0 // ì‚¬ìš© ì•ˆ í•¨
          }
        };
        
        onFaceAnalysis(faceData);
      }
    } catch (error) {
      console.error('í”„ë ˆì„ ë¶„ì„ ì‹¤íŒ¨:', error);
    }
    
    // ë²„í¼ ì´ˆê¸°í™” (ë‹¤ìŒ ì‹œí€€ìŠ¤ë¥¼ ìœ„í•´)
    frameBufferRef.current = [];
  };

  // ê°„ë‹¨í•œ ì–¼êµ´ ê°ì§€ ì‹œë®¬ë ˆì´ì…˜ (í”½ì…€ ë¶„ì„)
  const simulateFaceDetection = async (canvas: HTMLCanvasElement): Promise<boolean> => {
    const ctx = canvas.getContext('2d');
    if (!ctx) return false;

    try {
      // ì¤‘ì•™ ì˜ì—­ì˜ í”½ì…€ ë°ì´í„° ë¶„ì„
      const centerX = canvas.width / 2;
      const centerY = canvas.height / 2;
      const sampleSize = 50;

      const imageData = ctx.getImageData(
        centerX - sampleSize/2,
        centerY - sampleSize/2,
        sampleSize,
        sampleSize
      );

      // í”¼ë¶€ìƒ‰ ë²”ìœ„ ì²´í¬ (ë§¤ìš° ê°„ë‹¨í•œ ë°©ë²•)
      let skinPixels = 0;
      const data = imageData.data;

      for (let i = 0; i < data.length; i += 4) {
        const r = data[i];
        const g = data[i + 1];
        const b = data[i + 2];

        // ê°„ë‹¨í•œ í”¼ë¶€ìƒ‰ ê°ì§€
        if (r > 95 && g > 40 && b > 20 &&
            Math.max(r, g, b) - Math.min(r, g, b) > 15 &&
            Math.abs(r - g) > 15 && r > g && r > b) {
          skinPixels++;
        }
      }

      // í”½ì…€ì˜ 10% ì´ìƒì´ í”¼ë¶€ìƒ‰ì´ë©´ ì–¼êµ´ë¡œ ê°„ì£¼
      return skinPixels > (sampleSize * sampleSize * 0.1);
    } catch (error) {
      console.error('ì–¼êµ´ ê°ì§€ ì‹œë®¬ë ˆì´ì…˜ ì‹¤íŒ¨:', error);
      return false;
    }
  };

  // ì£¼ê¸°ì  ë¶„ì„ ì‹¤í–‰
  useEffect(() => {
    if (!isActive || !isWebcamActive) return;

    const interval = setInterval(captureAndAnalyze, frameInterval); // 200msë§ˆë‹¤ (5fps)

    return () => clearInterval(interval);
  }, [isActive, isWebcamActive, frameInterval]);

  // ì»´í¬ë„ŒíŠ¸ ë§ˆìš´íŠ¸/ì–¸ë§ˆìš´íŠ¸ ì‹œ ì›¹ìº  ê´€ë¦¬
  useEffect(() => {
    if (isActive && !useExistingStream) {
      // ìƒˆ ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ ìƒì„±
      startWebcam();
    } else if (isActive && useExistingStream) {
      // ê¸°ì¡´ ìŠ¤íŠ¸ë¦¼ ì‚¬ìš© - EyeTrackerì˜ ë¹„ë””ì˜¤ ê³µìœ 
      console.log('ğŸ¥ WebcamFaceDetection: ê¸°ì¡´ ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ ì‚¬ìš© ëª¨ë“œ');
      setIsWebcamActive(true);
      
      // EyeTrackerì˜ ë¹„ë””ì˜¤ ì°¾ì•„ì„œ í”„ë ˆì„ ìº¡ì²˜
      let attempts = 0;
      const maxAttempts = 20;
      
      const findAndUseExistingVideo = () => {
        attempts++;
        const eyeTrackerVideo = document.querySelector('.webcam-video') as HTMLVideoElement;
        
        console.log(`ğŸ” ë¹„ë””ì˜¤ ì°¾ê¸° ì‹œë„ ${attempts}/${maxAttempts}:`, {
          videoFound: !!eyeTrackerVideo,
          hasSrcObject: eyeTrackerVideo?.srcObject ? true : false,
          readyState: eyeTrackerVideo?.readyState
        });
        
        if (eyeTrackerVideo && eyeTrackerVideo.srcObject && eyeTrackerVideo.readyState >= 2) {
          console.log('âœ… CNN-LSTMìš© ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ê³µìœ  ì„±ê³µ!');
          // ë™ì¼í•œ ìŠ¤íŠ¸ë¦¼ì„ ì°¸ì¡°
          if (videoRef.current) {
            videoRef.current.srcObject = eyeTrackerVideo.srcObject;
            console.log('âœ… í”„ë ˆì„ ìº¡ì²˜ ì¤€ë¹„ ì™„ë£Œ');
          }
        } else if (attempts < maxAttempts) {
          console.log(`â³ EyeTracker ë¹„ë””ì˜¤ ëŒ€ê¸° ì¤‘... (${attempts}/${maxAttempts})`);
          setTimeout(findAndUseExistingVideo, 1000);
        } else {
          console.error('âŒ EyeTracker ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤');
        }
      };
      
      // ì´ˆê¸° ëŒ€ê¸° ì‹œê°„ì„ ëŠ˜ë¦¼
      setTimeout(findAndUseExistingVideo, 2000);
    } else if (!isActive) {
      stopWebcam();
    }

    return () => {
      if (!useExistingStream) {
        stopWebcam();
      }
    };
  }, [isActive, useExistingStream]);

  return (
    <div className="webcam-face-detection">
      {error && (
        <div className={`webcam-error ${isMockMode ? 'mock-mode' : ''}`}>
          <div className="error-icon"></div>
          <p>{error}</p>
          {!isMockMode && (
            <button onClick={startWebcam} className="retry-btn">
              ë‹¤ì‹œ ì‹œë„
            </button>
          )}
        </div>
      )}

      {isWebcamActive && (
        <div className="webcam-container">
          <div className="video-wrapper">
            <video
              ref={videoRef}
              autoPlay
              playsInline
              muted
              className="webcam-video"
            />

            {/* ì–¼êµ´ ê°ì§€ ìƒíƒœ í‘œì‹œ */}
            <div className={`detection-indicator ${faceDetected ? 'detected' : 'not-detected'}`}>
              <div className="indicator-dot"></div>
              <span>{faceDetected ? 'ì–¼êµ´ ê°ì§€ë¨' : 'ì–¼êµ´ì„ ì°¾ëŠ” ì¤‘...'}</span>
            </div>
          </div>

          {/* ìˆ¨ê²¨ì§„ ìº”ë²„ìŠ¤ (í”„ë ˆì„ ìº¡ì²˜ìš©) */}
          <canvas
            ref={canvasRef}
            style={{ display: 'none' }}
          />
        </div>
      )}

      {!isActive && (
        <div className="webcam-inactive">
          <div className="inactive-icon"></div>
          <p>ì›¹ìº ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤</p>
        </div>
      )}
    </div>
  );
};

export default WebcamFaceDetection;